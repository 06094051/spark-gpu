//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-19324607
// Cuda compilation tools, release 7.0, V7.0.27
// Based on LLVM 3.4svn
//

.version 4.2
.target sm_20
.address_size 64

	// .globl	_Z8identityPKiPil
.extern .func __assertfail
(
	.param .b64 __assertfail_param_0,
	.param .b64 __assertfail_param_1,
	.param .b32 __assertfail_param_2,
	.param .b64 __assertfail_param_3,
	.param .b64 __assertfail_param_4
)
;
.global .align 1 .b8 __T20[39] = {118, 111, 105, 100, 32, 115, 117, 109, 40, 105, 110, 116, 32, 42, 44, 32, 105, 110, 116, 32, 42, 44, 32, 108, 111, 110, 103, 44, 32, 105, 110, 116, 44, 32, 105, 110, 116, 41, 0};
.global .align 1 .b8 __T21[77] = {118, 111, 105, 100, 32, 105, 110, 116, 65, 114, 114, 97, 121, 83, 117, 109, 40, 99, 111, 110, 115, 116, 32, 108, 111, 110, 103, 32, 42, 44, 32, 99, 111, 110, 115, 116, 32, 99, 104, 97, 114, 32, 42, 44, 32, 108, 111, 110, 103, 32, 42, 44, 32, 99, 104, 97, 114, 32, 42, 44, 32, 108, 111, 110, 103, 44, 32, 105, 110, 116, 44, 32, 105, 110, 116, 41, 0};
.global .align 1 .b8 $str[31] = {106, 117, 109, 112, 32, 61, 61, 32, 98, 108, 111, 99, 107, 68, 105, 109, 46, 120, 32, 42, 32, 103, 114, 105, 100, 68, 105, 109, 46, 120, 0};
.global .align 1 .b8 $str1[19] = {116, 101, 115, 116, 67, 85, 68, 65, 75, 101, 114, 110, 101, 108, 115, 46, 99, 117, 0};

.visible .entry _Z8identityPKiPil(
	.param .u64 _Z8identityPKiPil_param_0,
	.param .u64 _Z8identityPKiPil_param_1,
	.param .u64 _Z8identityPKiPil_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .s32 	%r<5>;
	.reg .s64 	%rd<12>;


	ld.param.u64 	%rd2, [_Z8identityPKiPil_param_0];
	ld.param.u64 	%rd3, [_Z8identityPKiPil_param_1];
	ld.param.u64 	%rd4, [_Z8identityPKiPil_param_2];
	mov.u32 	%r1, %tid.x;
	cvt.u64.u32	%rd5, %r1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mul.wide.u32 	%rd6, %r3, %r2;
	add.s64 	%rd1, %rd6, %rd5;
	setp.ge.s64	%p1, %rd1, %rd4;
	@%p1 bra 	BB0_2;

	cvta.to.global.u64 	%rd7, %rd2;
	shl.b64 	%rd8, %rd1, 2;
	add.s64 	%rd9, %rd7, %rd8;
	ld.global.u32 	%r4, [%rd9];
	cvta.to.global.u64 	%rd10, %rd3;
	add.s64 	%rd11, %rd10, %rd8;
	st.global.u32 	[%rd11], %r4;

BB0_2:
	ret;
}

	// .globl	_Z16intArrayIdentityPKlPKcPlPcl
.visible .entry _Z16intArrayIdentityPKlPKcPlPcl(
	.param .u64 _Z16intArrayIdentityPKlPKcPlPcl_param_0,
	.param .u64 _Z16intArrayIdentityPKlPKcPlPcl_param_1,
	.param .u64 _Z16intArrayIdentityPKlPKcPlPcl_param_2,
	.param .u64 _Z16intArrayIdentityPKlPKcPlPcl_param_3,
	.param .u64 _Z16intArrayIdentityPKlPKcPlPcl_param_4
)
{
	.reg .pred 	%p<4>;
	.reg .s32 	%r<5>;
	.reg .s64 	%rd<32>;


	ld.param.u64 	%rd12, [_Z16intArrayIdentityPKlPKcPlPcl_param_0];
	ld.param.u64 	%rd14, [_Z16intArrayIdentityPKlPKcPlPcl_param_1];
	ld.param.u64 	%rd13, [_Z16intArrayIdentityPKlPKcPlPcl_param_2];
	ld.param.u64 	%rd15, [_Z16intArrayIdentityPKlPKcPlPcl_param_3];
	ld.param.u64 	%rd16, [_Z16intArrayIdentityPKlPKcPlPcl_param_4];
	cvta.to.global.u64 	%rd1, %rd15;
	cvta.to.global.u64 	%rd2, %rd14;
	mov.u32 	%r1, %tid.x;
	cvt.u64.u32	%rd17, %r1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mul.wide.u32 	%rd18, %r3, %r2;
	add.s64 	%rd3, %rd18, %rd17;
	setp.ge.s64	%p1, %rd3, %rd16;
	@%p1 bra 	BB1_5;

	cvta.to.global.u64 	%rd19, %rd12;
	shl.b64 	%rd20, %rd3, 3;
	add.s64 	%rd21, %rd19, %rd20;
	ld.global.u64 	%rd4, [%rd21];
	add.s64 	%rd22, %rd2, %rd4;
	ld.global.u64 	%rd5, [%rd22];
	ld.global.u64 	%rd6, [%rd22+8];
	setp.lt.s64	%p2, %rd6, 1;
	@%p2 bra 	BB1_4;

	add.s64 	%rd30, %rd4, 128;
	mov.u64 	%rd31, 0;

BB1_3:
	add.s64 	%rd24, %rd2, %rd30;
	ld.global.u32 	%r4, [%rd24];
	add.s64 	%rd25, %rd1, %rd30;
	st.global.u32 	[%rd25], %r4;
	add.s64 	%rd30, %rd30, 4;
	add.s64 	%rd31, %rd31, 1;
	setp.lt.s64	%p3, %rd31, %rd6;
	@%p3 bra 	BB1_3;

BB1_4:
	cvta.to.global.u64 	%rd26, %rd13;
	add.s64 	%rd27, %rd1, %rd4;
	add.s64 	%rd29, %rd26, %rd20;
	st.global.u64 	[%rd29], %rd4;
	st.global.u64 	[%rd27], %rd5;
	st.global.u64 	[%rd27+8], %rd6;

BB1_5:
	ret;
}

	// .globl	_Z20IntDataPointIdentityPKlPKiPKcPlPiPcl
.visible .entry _Z20IntDataPointIdentityPKlPKiPKcPlPiPcl(
	.param .u64 _Z20IntDataPointIdentityPKlPKiPKcPlPiPcl_param_0,
	.param .u64 _Z20IntDataPointIdentityPKlPKiPKcPlPiPcl_param_1,
	.param .u64 _Z20IntDataPointIdentityPKlPKiPKcPlPiPcl_param_2,
	.param .u64 _Z20IntDataPointIdentityPKlPKiPKcPlPiPcl_param_3,
	.param .u64 _Z20IntDataPointIdentityPKlPKiPKcPlPiPcl_param_4,
	.param .u64 _Z20IntDataPointIdentityPKlPKiPKcPlPiPcl_param_5,
	.param .u64 _Z20IntDataPointIdentityPKlPKiPKcPlPiPcl_param_6
)
{
	.reg .pred 	%p<4>;
	.reg .s32 	%r<6>;
	.reg .s64 	%rd<39>;


	ld.param.u64 	%rd12, [_Z20IntDataPointIdentityPKlPKiPKcPlPiPcl_param_0];
	ld.param.u64 	%rd13, [_Z20IntDataPointIdentityPKlPKiPKcPlPiPcl_param_1];
	ld.param.u64 	%rd16, [_Z20IntDataPointIdentityPKlPKiPKcPlPiPcl_param_2];
	ld.param.u64 	%rd14, [_Z20IntDataPointIdentityPKlPKiPKcPlPiPcl_param_3];
	ld.param.u64 	%rd15, [_Z20IntDataPointIdentityPKlPKiPKcPlPiPcl_param_4];
	ld.param.u64 	%rd17, [_Z20IntDataPointIdentityPKlPKiPKcPlPiPcl_param_5];
	ld.param.u64 	%rd18, [_Z20IntDataPointIdentityPKlPKiPKcPlPiPcl_param_6];
	cvta.to.global.u64 	%rd1, %rd17;
	cvta.to.global.u64 	%rd2, %rd16;
	mov.u32 	%r1, %tid.x;
	cvt.u64.u32	%rd19, %r1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mul.wide.u32 	%rd20, %r3, %r2;
	add.s64 	%rd3, %rd20, %rd19;
	setp.ge.s64	%p1, %rd3, %rd18;
	@%p1 bra 	BB2_5;

	cvta.to.global.u64 	%rd21, %rd12;
	shl.b64 	%rd22, %rd3, 3;
	add.s64 	%rd23, %rd21, %rd22;
	ld.global.u64 	%rd4, [%rd23];
	add.s64 	%rd24, %rd2, %rd4;
	ld.global.u64 	%rd5, [%rd24];
	ld.global.u64 	%rd6, [%rd24+8];
	setp.lt.s64	%p2, %rd6, 1;
	@%p2 bra 	BB2_4;

	add.s64 	%rd37, %rd4, 128;
	mov.u64 	%rd38, 0;

BB2_3:
	add.s64 	%rd26, %rd2, %rd37;
	ld.global.u32 	%r4, [%rd26];
	add.s64 	%rd27, %rd1, %rd37;
	st.global.u32 	[%rd27], %r4;
	add.s64 	%rd37, %rd37, 4;
	add.s64 	%rd38, %rd38, 1;
	setp.lt.s64	%p3, %rd38, %rd6;
	@%p3 bra 	BB2_3;

BB2_4:
	cvta.to.global.u64 	%rd28, %rd15;
	cvta.to.global.u64 	%rd29, %rd13;
	cvta.to.global.u64 	%rd30, %rd14;
	add.s64 	%rd31, %rd1, %rd4;
	add.s64 	%rd33, %rd30, %rd22;
	st.global.u64 	[%rd33], %rd4;
	st.global.u64 	[%rd31], %rd5;
	st.global.u64 	[%rd31+8], %rd6;
	shl.b64 	%rd34, %rd3, 2;
	add.s64 	%rd35, %rd29, %rd34;
	ld.global.u32 	%r5, [%rd35];
	add.s64 	%rd36, %rd28, %rd34;
	st.global.u32 	[%rd36], %r5;

BB2_5:
	ret;
}

	// .globl	_Z11intArrayAddPKlPKcPlPclPKi
.visible .entry _Z11intArrayAddPKlPKcPlPclPKi(
	.param .u64 _Z11intArrayAddPKlPKcPlPclPKi_param_0,
	.param .u64 _Z11intArrayAddPKlPKcPlPclPKi_param_1,
	.param .u64 _Z11intArrayAddPKlPKcPlPclPKi_param_2,
	.param .u64 _Z11intArrayAddPKlPKcPlPclPKi_param_3,
	.param .u64 _Z11intArrayAddPKlPKcPlPclPKi_param_4,
	.param .u64 _Z11intArrayAddPKlPKcPlPclPKi_param_5
)
{
	.reg .pred 	%p<4>;
	.reg .s32 	%r<7>;
	.reg .s64 	%rd<37>;


	ld.param.u64 	%rd15, [_Z11intArrayAddPKlPKcPlPclPKi_param_0];
	ld.param.u64 	%rd18, [_Z11intArrayAddPKlPKcPlPclPKi_param_1];
	ld.param.u64 	%rd16, [_Z11intArrayAddPKlPKcPlPclPKi_param_2];
	ld.param.u64 	%rd19, [_Z11intArrayAddPKlPKcPlPclPKi_param_3];
	ld.param.u64 	%rd20, [_Z11intArrayAddPKlPKcPlPclPKi_param_4];
	ld.param.u64 	%rd17, [_Z11intArrayAddPKlPKcPlPclPKi_param_5];
	cvta.to.global.u64 	%rd1, %rd19;
	cvta.to.global.u64 	%rd2, %rd18;
	mov.u32 	%r1, %tid.x;
	cvt.u64.u32	%rd21, %r1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mul.wide.u32 	%rd22, %r3, %r2;
	add.s64 	%rd3, %rd22, %rd21;
	setp.ge.s64	%p1, %rd3, %rd20;
	@%p1 bra 	BB3_5;

	cvta.to.global.u64 	%rd23, %rd15;
	shl.b64 	%rd24, %rd3, 3;
	add.s64 	%rd25, %rd23, %rd24;
	ld.global.u64 	%rd4, [%rd25];
	add.s64 	%rd26, %rd2, %rd4;
	ld.global.u64 	%rd5, [%rd26];
	ld.global.u64 	%rd6, [%rd26+8];
	setp.lt.s64	%p2, %rd6, 1;
	@%p2 bra 	BB3_4;

	cvta.to.global.u64 	%rd34, %rd17;
	add.s64 	%rd35, %rd4, 128;
	mov.u64 	%rd36, 0;

BB3_3:
	add.s64 	%rd28, %rd2, %rd35;
	ld.global.u32 	%r4, [%rd34];
	ld.global.u32 	%r5, [%rd28];
	add.s32 	%r6, %r4, %r5;
	add.s64 	%rd29, %rd1, %rd35;
	st.global.u32 	[%rd29], %r6;
	add.s64 	%rd35, %rd35, 4;
	add.s64 	%rd34, %rd34, 4;
	add.s64 	%rd36, %rd36, 1;
	setp.lt.s64	%p3, %rd36, %rd6;
	@%p3 bra 	BB3_3;

BB3_4:
	cvta.to.global.u64 	%rd30, %rd16;
	add.s64 	%rd31, %rd1, %rd4;
	add.s64 	%rd33, %rd30, %rd24;
	st.global.u64 	[%rd33], %rd4;
	st.global.u64 	[%rd31], %rd5;
	st.global.u64 	[%rd31+8], %rd6;

BB3_5:
	ret;
}

	// .globl	_Z12vectorLengthPKdS0_Pdl
.visible .entry _Z12vectorLengthPKdS0_Pdl(
	.param .u64 _Z12vectorLengthPKdS0_Pdl_param_0,
	.param .u64 _Z12vectorLengthPKdS0_Pdl_param_1,
	.param .u64 _Z12vectorLengthPKdS0_Pdl_param_2,
	.param .u64 _Z12vectorLengthPKdS0_Pdl_param_3
)
{
	.reg .pred 	%p<2>;
	.reg .s32 	%r<4>;
	.reg .f64 	%fd<6>;
	.reg .s64 	%rd<15>;


	ld.param.u64 	%rd2, [_Z12vectorLengthPKdS0_Pdl_param_0];
	ld.param.u64 	%rd3, [_Z12vectorLengthPKdS0_Pdl_param_1];
	ld.param.u64 	%rd4, [_Z12vectorLengthPKdS0_Pdl_param_2];
	ld.param.u64 	%rd5, [_Z12vectorLengthPKdS0_Pdl_param_3];
	mov.u32 	%r1, %tid.x;
	cvt.u64.u32	%rd6, %r1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mul.wide.u32 	%rd7, %r3, %r2;
	add.s64 	%rd1, %rd7, %rd6;
	setp.ge.s64	%p1, %rd1, %rd5;
	@%p1 bra 	BB4_2;

	cvta.to.global.u64 	%rd8, %rd2;
	shl.b64 	%rd9, %rd1, 3;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.f64 	%fd1, [%rd10];
	cvta.to.global.u64 	%rd11, %rd3;
	add.s64 	%rd12, %rd11, %rd9;
	ld.global.f64 	%fd2, [%rd12];
	mul.f64 	%fd3, %fd2, %fd2;
	fma.rn.f64 	%fd4, %fd1, %fd1, %fd3;
	sqrt.rn.f64 	%fd5, %fd4;
	cvta.to.global.u64 	%rd13, %rd4;
	add.s64 	%rd14, %rd13, %rd9;
	st.global.f64 	[%rd14], %fd5;

BB4_2:
	ret;
}

	// .globl	_Z9plusMinusPKdPKfPdPfl
.visible .entry _Z9plusMinusPKdPKfPdPfl(
	.param .u64 _Z9plusMinusPKdPKfPdPfl_param_0,
	.param .u64 _Z9plusMinusPKdPKfPdPfl_param_1,
	.param .u64 _Z9plusMinusPKdPKfPdPfl_param_2,
	.param .u64 _Z9plusMinusPKdPKfPdPfl_param_3,
	.param .u64 _Z9plusMinusPKdPKfPdPfl_param_4
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<4>;
	.reg .s32 	%r<4>;
	.reg .f64 	%fd<7>;
	.reg .s64 	%rd<19>;


	ld.param.u64 	%rd2, [_Z9plusMinusPKdPKfPdPfl_param_0];
	ld.param.u64 	%rd3, [_Z9plusMinusPKdPKfPdPfl_param_1];
	ld.param.u64 	%rd4, [_Z9plusMinusPKdPKfPdPfl_param_2];
	ld.param.u64 	%rd5, [_Z9plusMinusPKdPKfPdPfl_param_3];
	ld.param.u64 	%rd6, [_Z9plusMinusPKdPKfPdPfl_param_4];
	mov.u32 	%r1, %tid.x;
	cvt.u64.u32	%rd7, %r1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mul.wide.u32 	%rd8, %r3, %r2;
	add.s64 	%rd1, %rd8, %rd7;
	setp.ge.s64	%p1, %rd1, %rd6;
	@%p1 bra 	BB5_2;

	cvta.to.global.u64 	%rd9, %rd2;
	shl.b64 	%rd10, %rd1, 3;
	add.s64 	%rd11, %rd9, %rd10;
	cvta.to.global.u64 	%rd12, %rd3;
	shl.b64 	%rd13, %rd1, 2;
	add.s64 	%rd14, %rd12, %rd13;
	ld.global.f32 	%f1, [%rd14];
	cvt.ftz.f64.f32	%fd1, %f1;
	ld.global.f64 	%fd2, [%rd11];
	sub.f64 	%fd3, %fd2, %fd1;
	cvta.to.global.u64 	%rd15, %rd4;
	add.s64 	%rd16, %rd15, %rd10;
	st.global.f64 	[%rd16], %fd3;
	ld.global.f32 	%f2, [%rd14];
	cvt.ftz.f64.f32	%fd4, %f2;
	ld.global.f64 	%fd5, [%rd11];
	add.f64 	%fd6, %fd5, %fd4;
	cvt.rn.ftz.f32.f64	%f3, %fd6;
	cvta.to.global.u64 	%rd17, %rd5;
	add.s64 	%rd18, %rd17, %rd13;
	st.global.f32 	[%rd18], %f3;

BB5_2:
	ret;
}

	// .globl	_Z19applyLinearFunctionPKsPslss
.visible .entry _Z19applyLinearFunctionPKsPslss(
	.param .u64 _Z19applyLinearFunctionPKsPslss_param_0,
	.param .u64 _Z19applyLinearFunctionPKsPslss_param_1,
	.param .u64 _Z19applyLinearFunctionPKsPslss_param_2,
	.param .u16 _Z19applyLinearFunctionPKsPslss_param_3,
	.param .u16 _Z19applyLinearFunctionPKsPslss_param_4
)
{
	.reg .pred 	%p<2>;
	.reg .s16 	%rs<3>;
	.reg .s32 	%r<8>;
	.reg .s64 	%rd<12>;


	ld.param.u64 	%rd2, [_Z19applyLinearFunctionPKsPslss_param_0];
	ld.param.u64 	%rd3, [_Z19applyLinearFunctionPKsPslss_param_1];
	ld.param.u64 	%rd4, [_Z19applyLinearFunctionPKsPslss_param_2];
	ld.param.u16 	%rs1, [_Z19applyLinearFunctionPKsPslss_param_3];
	ld.param.u16 	%rs2, [_Z19applyLinearFunctionPKsPslss_param_4];
	mov.u32 	%r1, %tid.x;
	cvt.u64.u32	%rd5, %r1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mul.wide.u32 	%rd6, %r3, %r2;
	add.s64 	%rd1, %rd6, %rd5;
	setp.ge.s64	%p1, %rd1, %rd4;
	@%p1 bra 	BB6_2;

	cvta.to.global.u64 	%rd7, %rd2;
	shl.b64 	%rd8, %rd1, 1;
	add.s64 	%rd9, %rd7, %rd8;
	ld.global.s16 	%r4, [%rd9];
	cvt.s32.s16	%r5, %rs2;
	cvt.u32.u16	%r6, %rs1;
	mad.lo.s32 	%r7, %r4, %r5, %r6;
	cvta.to.global.u64 	%rd10, %rd3;
	add.s64 	%rd11, %rd10, %rd8;
	st.global.u16 	[%rd11], %r7;

BB6_2:
	ret;
}

	// .globl	_Z8blockXORPKcPcll
.visible .entry _Z8blockXORPKcPcll(
	.param .u64 _Z8blockXORPKcPcll_param_0,
	.param .u64 _Z8blockXORPKcPcll_param_1,
	.param .u64 _Z8blockXORPKcPcll_param_2,
	.param .u64 _Z8blockXORPKcPcll_param_3
)
{
	.reg .pred 	%p<2>;
	.reg .s32 	%r<4>;
	.reg .s64 	%rd<16>;


	ld.param.u64 	%rd2, [_Z8blockXORPKcPcll_param_0];
	ld.param.u64 	%rd3, [_Z8blockXORPKcPcll_param_1];
	ld.param.u64 	%rd5, [_Z8blockXORPKcPcll_param_2];
	ld.param.u64 	%rd4, [_Z8blockXORPKcPcll_param_3];
	mov.u32 	%r1, %tid.x;
	cvt.u64.u32	%rd6, %r1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mul.wide.u32 	%rd7, %r3, %r2;
	add.s64 	%rd1, %rd7, %rd6;
	shl.b64 	%rd8, %rd1, 3;
	setp.ge.s64	%p1, %rd8, %rd5;
	@%p1 bra 	BB7_2;

	cvta.to.global.u64 	%rd9, %rd2;
	add.s64 	%rd11, %rd9, %rd8;
	ld.global.u64 	%rd12, [%rd11];
	xor.b64  	%rd13, %rd12, %rd4;
	cvta.to.global.u64 	%rd14, %rd3;
	add.s64 	%rd15, %rd14, %rd8;
	st.global.u64 	[%rd15], %rd13;

BB7_2:
	ret;
}

	// .globl	_Z11multiplyBy2PiS_l
.visible .entry _Z11multiplyBy2PiS_l(
	.param .u64 _Z11multiplyBy2PiS_l_param_0,
	.param .u64 _Z11multiplyBy2PiS_l_param_1,
	.param .u64 _Z11multiplyBy2PiS_l_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .s32 	%r<7>;
	.reg .s64 	%rd<10>;


	ld.param.u64 	%rd1, [_Z11multiplyBy2PiS_l_param_0];
	ld.param.u64 	%rd2, [_Z11multiplyBy2PiS_l_param_1];
	ld.param.u64 	%rd3, [_Z11multiplyBy2PiS_l_param_2];
	mov.u32 	%r2, %tid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %ctaid.x;
	mad.lo.s32 	%r1, %r3, %r4, %r2;
	cvt.s64.s32	%rd4, %r1;
	setp.ge.s64	%p1, %rd4, %rd3;
	@%p1 bra 	BB8_2;

	cvta.to.global.u64 	%rd5, %rd1;
	mul.wide.s32 	%rd6, %r1, 4;
	add.s64 	%rd7, %rd5, %rd6;
	ld.global.u32 	%r5, [%rd7];
	shl.b32 	%r6, %r5, 1;
	cvta.to.global.u64 	%rd8, %rd2;
	add.s64 	%rd9, %rd8, %rd6;
	st.global.u32 	[%rd9], %r6;

BB8_2:
	ret;
}

	// .globl	_Z3sumPiS_lii
.visible .entry _Z3sumPiS_lii(
	.param .u64 _Z3sumPiS_lii_param_0,
	.param .u64 _Z3sumPiS_lii_param_1,
	.param .u64 _Z3sumPiS_lii_param_2,
	.param .u32 _Z3sumPiS_lii_param_3,
	.param .u32 _Z3sumPiS_lii_param_4
)
{
	.reg .pred 	%p<8>;
	.reg .s32 	%r<22>;
	.reg .s64 	%rd<38>;


	ld.param.u64 	%rd15, [_Z3sumPiS_lii_param_0];
	ld.param.u64 	%rd13, [_Z3sumPiS_lii_param_1];
	ld.param.u64 	%rd14, [_Z3sumPiS_lii_param_2];
	ld.param.u32 	%r9, [_Z3sumPiS_lii_param_3];
	cvta.to.global.u64 	%rd34, %rd15;
	mov.u32 	%r1, %tid.x;
	cvt.u64.u32	%rd16, %r1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mul.wide.u32 	%rd17, %r3, %r2;
	add.s64 	%rd2, %rd17, %rd16;
	setp.eq.s32	%p1, %r9, 0;
	@%p1 bra 	BB9_5;

	setp.ne.s64	%p2, %rd2, 0;
	@%p2 bra 	BB9_11;

	mov.u64 	%rd19, 16384;
	min.s64 	%rd3, %rd14, %rd19;
	mov.u32 	%r19, 0;
	mov.u32 	%r20, %r19;
	mov.u64 	%rd35, 0;
	setp.lt.s64	%p3, %rd3, 1;
	@%p3 bra 	BB9_4;

BB9_3:
	ld.global.u32 	%r12, [%rd34];
	add.s32 	%r20, %r12, %r20;
	add.s64 	%rd34, %rd34, 4;
	add.s64 	%rd35, %rd35, 1;
	setp.lt.s64	%p4, %rd35, %rd3;
	mov.u32 	%r19, %r20;
	@%p4 bra 	BB9_3;

BB9_4:
	cvta.to.global.u64 	%rd20, %rd13;
	st.global.u32 	[%rd20], %r19;
	bra.uni 	BB9_11;

BB9_5:
	setp.ge.s64	%p5, %rd2, %rd14;
	@%p5 bra 	BB9_11;

	mov.u32 	%r13, %nctaid.x;
	mul.lo.s32 	%r14, %r13, %r3;
	setp.eq.s32	%p6, %r14, 16384;
	@%p6 bra 	BB9_8;

	mov.u64 	%rd21, $str;
	cvta.global.u64 	%rd22, %rd21;
	mov.u64 	%rd23, $str1;
	cvta.global.u64 	%rd24, %rd23;
	mov.u64 	%rd25, __T20;
	cvta.global.u64 	%rd26, %rd25;
	mov.u32 	%r15, 135;
	mov.u64 	%rd27, 1;
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd22;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd24;
	.param .b32 param2;
	st.param.b32	[param2+0], %r15;
	.param .b64 param3;
	st.param.b64	[param3+0], %rd26;
	.param .b64 param4;
	st.param.b64	[param4+0], %rd27;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	
	//{
	}// Callseq End 0

BB9_8:
	add.s64 	%rd30, %rd17, %rd16;
	shl.b64 	%rd31, %rd30, 2;
	add.s64 	%rd36, %rd34, %rd31;
	mov.u32 	%r21, 0;
	mov.u64 	%rd37, %rd2;

BB9_9:
	mov.u64 	%rd10, %rd37;
	ld.global.u32 	%r17, [%rd36];
	add.s32 	%r21, %r17, %r21;
	add.s64 	%rd36, %rd36, 65536;
	add.s64 	%rd12, %rd10, 16384;
	setp.lt.s64	%p7, %rd12, %rd14;
	mov.u64 	%rd37, %rd12;
	@%p7 bra 	BB9_9;

	shl.b64 	%rd32, %rd2, 2;
	add.s64 	%rd33, %rd34, %rd32;
	st.global.u32 	[%rd33], %r21;

BB9_11:
	ret;
}

	// .globl	_Z11intArraySumPKlPKcPlPclii
.visible .entry _Z11intArraySumPKlPKcPlPclii(
	.param .u64 _Z11intArraySumPKlPKcPlPclii_param_0,
	.param .u64 _Z11intArraySumPKlPKcPlPclii_param_1,
	.param .u64 _Z11intArraySumPKlPKcPlPclii_param_2,
	.param .u64 _Z11intArraySumPKlPKcPlPclii_param_3,
	.param .u64 _Z11intArraySumPKlPKcPlPclii_param_4,
	.param .u32 _Z11intArraySumPKlPKcPlPclii_param_5,
	.param .u32 _Z11intArraySumPKlPKcPlPclii_param_6
)
{
	.reg .pred 	%p<17>;
	.reg .s32 	%r<15>;
	.reg .s64 	%rd<89>;


	ld.param.u64 	%rd40, [_Z11intArraySumPKlPKcPlPclii_param_0];
	ld.param.u64 	%rd43, [_Z11intArraySumPKlPKcPlPclii_param_1];
	ld.param.u64 	%rd41, [_Z11intArraySumPKlPKcPlPclii_param_2];
	ld.param.u64 	%rd44, [_Z11intArraySumPKlPKcPlPclii_param_3];
	ld.param.u64 	%rd42, [_Z11intArraySumPKlPKcPlPclii_param_4];
	ld.param.u32 	%r2, [_Z11intArraySumPKlPKcPlPclii_param_5];
	cvta.to.global.u64 	%rd1, %rd44;
	cvta.to.global.u64 	%rd2, %rd43;
	cvta.to.global.u64 	%rd3, %rd40;
	mov.u32 	%r3, %tid.x;
	cvt.u64.u32	%rd45, %r3;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r1, %ntid.x;
	mul.wide.u32 	%rd46, %r1, %r4;
	add.s64 	%rd4, %rd46, %rd45;
	setp.eq.s32	%p1, %r2, 0;
	@%p1 bra 	BB10_12;

	setp.ne.s64	%p2, %rd4, 0;
	@%p2 bra 	BB10_20;

	mov.u64 	%rd49, 16384;
	min.s64 	%rd5, %rd42, %rd49;
	ldu.global.u64 	%rd6, [%rd3];
	mov.u64 	%rd48, 0;
	mov.u64 	%rd84, %rd48;
	setp.lt.s64	%p3, %rd5, 1;
	mov.u64 	%rd85, %rd48;
	@%p3 bra 	BB10_10;

	add.s64 	%rd51, %rd6, %rd1;
	add.s64 	%rd7, %rd51, 128;
	add.s64 	%rd8, %rd2, 128;
	mov.u64 	%rd50, 0;
	mov.u64 	%rd9, %rd7;
	mov.u64 	%rd76, %rd6;
	mov.u64 	%rd80, %rd50;
	bra.uni 	BB10_4;

BB10_11:
	shl.b64 	%rd59, %rd80, 3;
	add.s64 	%rd60, %rd3, %rd59;
	ld.global.u64 	%rd28, [%rd60];
	mov.u64 	%rd76, %rd28;

BB10_4:
	mov.u64 	%rd10, %rd76;
	add.s64 	%rd53, %rd2, %rd10;
	ld.global.u64 	%rd12, [%rd53];
	ld.global.u64 	%rd84, [%rd53+8];
	setp.gt.s64	%p4, %rd84, 0;
	setp.eq.s64	%p5, %rd80, 0;
	and.pred  	%p6, %p5, %p4;
	mov.u64 	%rd77, %rd7;
	mov.u64 	%rd79, %rd50;
	@!%p6 bra 	BB10_6;
	bra.uni 	BB10_5;

BB10_5:
	mov.u64 	%rd15, %rd79;
	mov.u64 	%rd14, %rd77;
	mov.u32 	%r5, 0;
	st.global.u32 	[%rd14], %r5;
	add.s64 	%rd16, %rd14, 4;
	add.s64 	%rd17, %rd15, 1;
	setp.lt.s64	%p7, %rd17, %rd84;
	mov.u64 	%rd77, %rd16;
	mov.u64 	%rd79, %rd17;
	@%p7 bra 	BB10_5;

BB10_6:
	setp.lt.s64	%p8, %rd84, 1;
	@%p8 bra 	BB10_9;

	add.s64 	%rd82, %rd8, %rd10;
	mov.u64 	%rd83, 0;
	mov.u64 	%rd81, %rd9;

BB10_8:
	mov.u64 	%rd19, %rd81;
	ld.global.u32 	%r6, [%rd19];
	ld.global.u32 	%r7, [%rd82];
	add.s32 	%r8, %r6, %r7;
	st.global.u32 	[%rd19], %r8;
	add.s64 	%rd82, %rd82, 4;
	add.s64 	%rd23, %rd19, 4;
	add.s64 	%rd83, %rd83, 1;
	setp.lt.s64	%p9, %rd83, %rd84;
	mov.u64 	%rd81, %rd23;
	@%p9 bra 	BB10_8;

BB10_9:
	add.s64 	%rd80, %rd80, 1;
	setp.lt.s64	%p10, %rd80, %rd5;
	mov.u64 	%rd85, %rd12;
	@%p10 bra 	BB10_11;

BB10_10:
	mov.u64 	%rd27, %rd85;
	add.s64 	%rd55, %rd1, %rd6;
	cvta.to.global.u64 	%rd56, %rd41;
	st.global.u64 	[%rd56], %rd48;
	st.global.u64 	[%rd55], %rd27;
	st.global.u64 	[%rd55+8], %rd84;
	bra.uni 	BB10_20;

BB10_12:
	setp.ge.s64	%p11, %rd4, %rd42;
	@%p11 bra 	BB10_20;

	mov.u32 	%r9, %nctaid.x;
	mul.lo.s32 	%r10, %r9, %r1;
	setp.eq.s32	%p12, %r10, 16384;
	@%p12 bra 	BB10_15;

	mov.u64 	%rd61, $str;
	cvta.global.u64 	%rd62, %rd61;
	mov.u64 	%rd63, $str1;
	cvta.global.u64 	%rd64, %rd63;
	mov.u64 	%rd65, __T21;
	cvta.global.u64 	%rd66, %rd65;
	mov.u32 	%r11, 158;
	mov.u64 	%rd67, 1;
	// Callseq Start 1
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd62;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd64;
	.param .b32 param2;
	st.param.b32	[param2+0], %r11;
	.param .b64 param3;
	st.param.b64	[param3+0], %rd66;
	.param .b64 param4;
	st.param.b64	[param4+0], %rd67;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	
	//{
	}// Callseq End 1

BB10_15:
	add.s64 	%rd86, %rd4, 16384;
	setp.ge.s64	%p13, %rd86, %rd42;
	@%p13 bra 	BB10_20;

	shl.b64 	%rd68, %rd4, 3;
	add.s64 	%rd69, %rd3, %rd68;
	ld.global.u64 	%rd30, [%rd69];
	add.s64 	%rd31, %rd2, 128;

BB10_17:
	shl.b64 	%rd71, %rd86, 3;
	add.s64 	%rd72, %rd3, %rd71;
	ld.global.u64 	%rd33, [%rd72];
	add.s64 	%rd73, %rd33, %rd2;
	ld.global.u64 	%rd34, [%rd73+8];
	mov.u64 	%rd88, 0;
	setp.lt.s64	%p14, %rd34, 1;
	mov.u64 	%rd87, %rd31;
	@%p14 bra 	BB10_19;

BB10_18:
	mov.u64 	%rd35, %rd87;
	add.s64 	%rd74, %rd35, %rd33;
	add.s64 	%rd75, %rd35, %rd30;
	ld.global.u32 	%r12, [%rd75];
	ld.global.u32 	%r13, [%rd74];
	add.s32 	%r14, %r12, %r13;
	st.global.u32 	[%rd75], %r14;
	add.s64 	%rd37, %rd35, 4;
	add.s64 	%rd88, %rd88, 1;
	setp.lt.s64	%p15, %rd88, %rd34;
	mov.u64 	%rd87, %rd37;
	@%p15 bra 	BB10_18;

BB10_19:
	add.s64 	%rd86, %rd86, 16384;
	setp.lt.s64	%p16, %rd86, %rd42;
	@%p16 bra 	BB10_17;

BB10_20:
	ret;
}

	// .globl	_Z12DataPointMapPKlPKiPKcPlPcl
.visible .entry _Z12DataPointMapPKlPKiPKcPlPcl(
	.param .u64 _Z12DataPointMapPKlPKiPKcPlPcl_param_0,
	.param .u64 _Z12DataPointMapPKlPKiPKcPlPcl_param_1,
	.param .u64 _Z12DataPointMapPKlPKiPKcPlPcl_param_2,
	.param .u64 _Z12DataPointMapPKlPKiPKcPlPcl_param_3,
	.param .u64 _Z12DataPointMapPKlPKiPKcPlPcl_param_4,
	.param .u64 _Z12DataPointMapPKlPKiPKcPlPcl_param_5
)
{
	.reg .pred 	%p<4>;
	.reg .s32 	%r<4>;
	.reg .f64 	%fd<2>;
	.reg .s64 	%rd<32>;


	ld.param.u64 	%rd12, [_Z12DataPointMapPKlPKiPKcPlPcl_param_0];
	ld.param.u64 	%rd14, [_Z12DataPointMapPKlPKiPKcPlPcl_param_2];
	ld.param.u64 	%rd13, [_Z12DataPointMapPKlPKiPKcPlPcl_param_3];
	ld.param.u64 	%rd15, [_Z12DataPointMapPKlPKiPKcPlPcl_param_4];
	ld.param.u64 	%rd16, [_Z12DataPointMapPKlPKiPKcPlPcl_param_5];
	cvta.to.global.u64 	%rd1, %rd15;
	cvta.to.global.u64 	%rd2, %rd14;
	mov.u32 	%r1, %tid.x;
	cvt.u64.u32	%rd17, %r1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mul.wide.u32 	%rd18, %r3, %r2;
	add.s64 	%rd3, %rd18, %rd17;
	setp.ge.s64	%p1, %rd3, %rd16;
	@%p1 bra 	BB11_5;

	cvta.to.global.u64 	%rd19, %rd12;
	shl.b64 	%rd20, %rd3, 3;
	add.s64 	%rd21, %rd19, %rd20;
	ld.global.u64 	%rd4, [%rd21];
	add.s64 	%rd22, %rd2, %rd4;
	ld.global.u64 	%rd5, [%rd22];
	ld.global.u64 	%rd6, [%rd22+8];
	setp.lt.s64	%p2, %rd6, 1;
	@%p2 bra 	BB11_4;

	add.s64 	%rd30, %rd4, 128;
	mov.u64 	%rd31, 0;

BB11_3:
	add.s64 	%rd24, %rd2, %rd30;
	ld.global.f64 	%fd1, [%rd24];
	add.s64 	%rd25, %rd1, %rd30;
	st.global.f64 	[%rd25], %fd1;
	add.s64 	%rd30, %rd30, 8;
	add.s64 	%rd31, %rd31, 1;
	setp.lt.s64	%p3, %rd31, %rd6;
	@%p3 bra 	BB11_3;

BB11_4:
	cvta.to.global.u64 	%rd26, %rd13;
	add.s64 	%rd27, %rd1, %rd4;
	add.s64 	%rd29, %rd26, %rd20;
	st.global.u64 	[%rd29], %rd4;
	st.global.u64 	[%rd27], %rd5;
	st.global.u64 	[%rd27+8], %rd6;

BB11_5:
	ret;
}


